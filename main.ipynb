{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2df5a8a-9e8f-4d70-9a71-892342cdb616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2574a232-1f4f-405c-bad8-40e386f21e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'AdaFace' already exists and is not an empty directory.\n",
      "fatal: destination path 'python-utils' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# githubリポジトリをクローン\n",
    "!git clone https://github.com/mk-minchul/AdaFace.git\n",
    "!git clone https://github.com/afm215/python-utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53de6f77-86e2-4a3f-b630-71e86e467ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.1\n",
      "    Uninstalling pip-23.3.1:\n",
      "      Successfully uninstalled pip-23.3.1\n",
      "Successfully installed pip-25.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
      "Collecting tqdm (from gdown)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, PySocks, gdown\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [gdown]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PySocks-1.7.1 gdown-5.2.0 tqdm-4.67.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pytorch-lightning==1.8.6 (from -r requirements.txt (line 1))\n",
      "  Downloading pytorch_lightning-1.8.6-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting torch<=1.13.1 (from -r requirements.txt (line 2))\n",
      "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.67.1)\n",
      "Collecting bcolz-zipline (from -r requirements.txt (line 4))\n",
      "  Downloading bcolz_zipline-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting prettytable (from -r requirements.txt (line 5))\n",
      "  Downloading prettytable-3.16.0-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting menpo (from -r requirements.txt (line 6))\n",
      "  Downloading menpo-0.11.1.tar.gz (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting mxnet (from -r requirements.txt (line 7))\n",
      "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting opencv-python (from -r requirements.txt (line 8))\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 9))\n",
      "  Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting torchvision<=0.14.1 (from -r requirements.txt (line 10))\n",
      "  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "Collecting pandas (from -r requirements.txt (line 11))\n",
      "  Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy<=1.23 (from -r requirements.txt (line 12))\n",
      "  Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.8.6->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.8.6->-r requirements.txt (line 1)) (2023.4.0)\n",
      "Collecting tensorboardX>=2.2 (from pytorch-lightning==1.8.6->-r requirements.txt (line 1))\n",
      "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==1.8.6->-r requirements.txt (line 1))\n",
      "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.8.6->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.8.6->-r requirements.txt (line 1)) (4.4.0)\n",
      "Collecting lightning-utilities!=0.4.0,>=0.3.0 (from pytorch-lightning==1.8.6->-r requirements.txt (line 1))\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<=1.13.1->-r requirements.txt (line 2))\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch<=1.13.1->-r requirements.txt (line 2))\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch<=1.13.1->-r requirements.txt (line 2))\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<=1.13.1->-r requirements.txt (line 2))\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<=1.13.1->-r requirements.txt (line 2)) (68.2.2)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<=1.13.1->-r requirements.txt (line 2)) (0.41.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision<=0.14.1->-r requirements.txt (line 10)) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision<=0.14.1->-r requirements.txt (line 10)) (9.3.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->-r requirements.txt (line 5)) (0.2.9)\n",
      "Collecting scipy>=1.0 (from menpo->-r requirements.txt (line 6))\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting matplotlib>=3.0 (from menpo->-r requirements.txt (line 6))\n",
      "  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet->-r requirements.txt (line 7))\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision<=0.14.1->-r requirements.txt (line 10)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision<=0.14.1->-r requirements.txt (line 10)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision<=0.14.1->-r requirements.txt (line 10)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision<=0.14.1->-r requirements.txt (line 10)) (2022.12.7)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 9))\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r requirements.txt (line 9))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 11)) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 11))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 11))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning==1.8.6->-r requirements.txt (line 1))\n",
      "  Downloading aiohttp-3.12.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6->-r requirements.txt (line 1))\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6->-r requirements.txt (line 1))\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6->-r requirements.txt (line 1))\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6->-r requirements.txt (line 1)) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6->-r requirements.txt (line 1))\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6->-r requirements.txt (line 1))\n",
      "  Downloading multidict-6.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6->-r requirements.txt (line 1))\n",
      "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.6->-r requirements.txt (line 1))\n",
      "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.0->menpo->-r requirements.txt (line 6))\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.0->menpo->-r requirements.txt (line 6))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.0->menpo->-r requirements.txt (line 6))\n",
      "  Downloading fonttools-4.58.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.0->menpo->-r requirements.txt (line 6))\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.0->menpo->-r requirements.txt (line 6)) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 11)) (1.16.0)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy>=1.0 (from menpo->-r requirements.txt (line 6))\n",
      "  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "  Downloading scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "  Downloading scipy-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting protobuf>=3.20 (from tensorboardX>=2.2->pytorch-lightning==1.8.6->-r requirements.txt (line 1))\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "INFO: pip is looking at multiple versions of torchmetrics to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==1.8.6->-r requirements.txt (line 1))\n",
      "  Downloading torchmetrics-1.7.2-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading torchmetrics-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading torchmetrics-1.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading torchmetrics-1.6.2-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "INFO: pip is still looking at multiple versions of torchmetrics to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchmetrics-1.5.2-py3-none-any.whl.metadata (20 kB)\n",
      "Downloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m155.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bcolz_zipline-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prettytable-3.16.0-py3-none-any.whl (33 kB)\n",
      "Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m149.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (226 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m155.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading torchmetrics-1.5.2-py3-none-any.whl (891 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.4/891.4 kB\u001b[0m \u001b[31m126.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Building wheels for collected packages: menpo\n",
      "  Building wheel for menpo (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for menpo: filename=menpo-0.11.1-py3-none-any.whl size=1611935 sha256=a30b3a74ac84e9f11093f29519a19553e3aae370ff6a2a2b7959f6a8a150d9f8\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/48/f0/92c6393a62993b504063ca372e77149f05f1964db1fd0639d3\n",
      "Successfully built menpo\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, protobuf, propcache, prettytable, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, multidict, lightning-utilities, kiwisolver, joblib, graphviz, frozenlist, fonttools, cycler, async-timeout, aiohappyeyeballs, yarl, tensorboardX, scipy, pandas, opencv-python, nvidia-cudnn-cu11, mxnet, contourpy, bcolz-zipline, aiosignal, torch, scikit-learn, matplotlib, aiohttp, torchvision, torchmetrics, menpo, pytorch-lightning\n",
      "\u001b[2K  Attempting uninstall: numpym\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/38\u001b[0m [nvidia-cublas-cu11]u11]\n",
      "\u001b[2K    Found existing installation: numpy 1.24.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/38\u001b[0m [nvidia-cublas-cu11]\n",
      "\u001b[2K    Uninstalling numpy-1.24.1:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/38\u001b[0m [nvidia-cublas-cu11]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.24.1━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/38\u001b[0m [numpy]las-cu11]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m28/38\u001b[0m [bcolz-zipline]u11]\n",
      "\u001b[2K    Found existing installation: torch 2.1.0+cu1180m━━━━━━━━━━\u001b[0m \u001b[32m28/38\u001b[0m [bcolz-zipline]\n",
      "\u001b[2K    Uninstalling torch-2.1.0+cu118:━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m30/38\u001b[0m [torch]ine]\n",
      "\u001b[2K      Successfully uninstalled torch-2.1.0+cu118╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m30/38\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m33/38\u001b[0m [aiohttp]ib]n]\n",
      "\u001b[2K    Found existing installation: torchvision 0.16.0+cu118━━━━━\u001b[0m \u001b[32m33/38\u001b[0m [aiohttp]\n",
      "\u001b[2K    Uninstalling torchvision-0.16.0+cu118:━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m34/38\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.16.0+cu1180m\u001b[90m━━━━\u001b[0m \u001b[32m34/38\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38/38\u001b[0m [pytorch-lightning]pytorch-lightning]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 async-timeout-5.0.1 bcolz-zipline-1.13.0 contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.4 frozenlist-1.7.0 graphviz-0.8.4 joblib-1.5.1 kiwisolver-1.4.8 lightning-utilities-0.14.3 matplotlib-3.10.3 menpo-0.11.1 multidict-6.5.0 mxnet-1.9.1 numpy-1.23.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 opencv-python-4.11.0.86 pandas-2.3.0 prettytable-3.16.0 propcache-0.3.2 protobuf-6.31.1 pytorch-lightning-1.8.6 pytz-2025.2 scikit-learn-1.7.0 scipy-1.13.1 tensorboardX-2.6.4 threadpoolctl-3.6.0 torch-1.13.1 torchmetrics-1.5.2 torchvision-0.14.1 tzdata-2025.2 yarl-1.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mObtaining file:///workspace/python-utils\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: own-utils\n",
      "\u001b[33m  DEPRECATION: Legacy editable install of own-utils==0.1.18 from file:///workspace/python-utils (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py develop for own-utils\n",
      "Successfully installed own-utils\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 各ライブラリのインストール\n",
    "!python -m pip install --upgrade pip\n",
    "!pip install gdown\n",
    "!pip install -r requirements.txt\n",
    "!pip install -e ./python-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0057808d-c169-4513-9e4c-68ba9324aaf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 19 16:20:58 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX 2000 Ada Gene...    On  |   00000000:C2:00.0 Off |                  Off |\n",
      "| 30%   27C    P8              6W /   70W |       2MiB /  16380MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd0b4206-d6c1-43f8-839e-804097859bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 1.13.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: nvidia-cublas-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-runtime-cu11, nvidia-cudnn-cu11, typing-extensions\n",
      "Required-by: pytorch-lightning, torchaudio, torchmetrics, torchvision\n",
      "---\n",
      "Name: torchvision\n",
      "Version: 0.14.1\n",
      "Summary: image and video datasets and models for torch deep learning\n",
      "Home-page: https://github.com/pytorch/vision\n",
      "Author: PyTorch Core Team\n",
      "Author-email: soumith@pytorch.org\n",
      "License: BSD\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: numpy, pillow, requests, torch, typing-extensions\n",
      "Required-by: \n",
      "---\n",
      "Name: torchaudio\n",
      "Version: 2.1.0+cu118\n",
      "Summary: An audio package for PyTorch\n",
      "Home-page: https://github.com/pytorch/audio\n",
      "Author: Soumith Chintala, David Pollack, Sean Naren, Peter Goldsborough, Moto Hira, Caroline Chen, Jeff Hwang, Zhaoheng Ni, Xiaohui Zhang\n",
      "Author-email: soumith@pytorch.org\n",
      "License: \n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: torch\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296f97e5-de16-4a75-b876-6c5e745d5031",
   "metadata": {},
   "source": [
    "# CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce1dce2c-124a-44ff-8b97-edea696977b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class CONFIG:\n",
    "    \n",
    "    # デバックモード\n",
    "    is_debug_mode = True\n",
    "    max_images_num = 5\n",
    "\n",
    "    # データセットの指定\n",
    "    is_original_dataset = False\n",
    "    dataset_name = 'faces_webface_112x112' if not is_original_dataset else 'original'\n",
    "    dataset_dir = os.path.join(\"data\", dataset_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e185db08-5ed4-4a9c-8d39-3cb0f6d33010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "if not os.path.isdir(CONFIG.dataset_dir):\n",
    "    if CONFIG.dataset_name == 'faces_umd':\n",
    "        #UMD-facesをダウンロード\n",
    "        file_id = '1azhEHoJjVmifuzBVKJwl-sDbLZ-Wzp4O'\n",
    "        gdown.download(f\"https://drive.google.com/uc?id={file_id}\", f\"{CONFIG.dataset_name}.zip\", quiet=False)\n",
    "        #zip解凍\n",
    "        with zipfile.ZipFile(f\"{CONFIG.dataset_name}.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"data\")  # 任意の展開先フォルダ\n",
    "    if CONFIG.dataset_name == 'faces_webface_112x112':\n",
    "        # CASIA-webfaceをダウンロード\n",
    "        file_id = '1KxNCrXzln0lal3N4JiYl9cFOIhT78y1l'\n",
    "        gdown.download(f\"https://drive.google.com/uc?id={file_id}\", f\"{CONFIG.dataset_name}.zip\", quiet=False)\n",
    "        #zip解凍\n",
    "        with zipfile.ZipFile(f\"{CONFIG.dataset_name}.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"data\")  # 任意の展開先フォルダ\n",
    "\n",
    "    if CONFIG.dataset_name == 'original':\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "697d2c0a-457a-4045-8ded-dfff5a2e853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c716038-1840-4d41-933d-59458df28fdb",
   "metadata": {},
   "source": [
    "# rec file convert to image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9146673a-f5b4-4e79-8d60-b9274b648b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{CONFIG.dataset_dir}/imgs\") and not CONFIG.is_original_dataset: # InsightFaceDataset\n",
    "    !python AdaFace/convert.py --rec_path {dataset_dir} --make_image_files --make_validation_memfiles\n",
    "elif not os.path.exists(f\"{CONFIG.dataset_dir}\") and CONFIG.is_original_dataset: # OriginalFaceDataset\n",
    "    pass\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2fc5af4-f404-455a-ae90-623faa7ac9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data_root: data\n",
      " dataset_dir: data/faces_webface_112x112\n",
      " dataset_img_dir:data/faces_webface_112x112/imgs\n"
     ]
    }
   ],
   "source": [
    "data_root = os.path.dirname(CONFIG.dataset_dir) \n",
    "dataset_dir = CONFIG.dataset_dir\n",
    "dataset_img_dir = os.path.join(CONFIG.dataset_dir, \"imgs\")\n",
    "\n",
    "print(f\" data_root: {data_root}\\n dataset_dir: {dataset_dir}\\n dataset_img_dir:{dataset_img_dir}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "600355b0-4d15-46dc-b105-50a3032e2783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data_root: data\n",
      " dataset_dir: data/debug_dataset\n",
      " dataset_img_dir:data/debug_dataset/imgs\n",
      "▶ Using dataset_path : data/debug_dataset\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "debug_dir = os.path.join(data_root, \"debug_dataset\")\n",
    "debug_img_dir = os.path.join(debug_dir, \"imgs\") \n",
    "\n",
    "if CONFIG.is_debug_mode:\n",
    "\n",
    "    # 既存フォルダをクリア\n",
    "    if os.path.isdir(debug_dir):\n",
    "        shutil.rmtree(debug_dir)\n",
    "    os.makedirs(debug_dir, exist_ok=True)\n",
    "\n",
    "    # クラス名ディレクトリをソートして先頭5つ取得\n",
    "    class_dirs = sorted([\n",
    "        d for d in os.listdir(dataset_img_dir)\n",
    "        if os.path.isdir(os.path.join(dataset_img_dir, d))\n",
    "    ])[:CONFIG.max_images_num]\n",
    "\n",
    "    # 画像データをコピー\n",
    "    for cls in class_dirs:\n",
    "        src = os.path.join(dataset_img_dir, cls)\n",
    "        dst = os.path.join(debug_img_dir, cls)\n",
    "        shutil.copytree(src, dst)\n",
    "        # もしくは高速に済ませたいなら symlink:\n",
    "        # os.symlink(src, dst, target_is_directory=True)\n",
    "\n",
    "    # dataset_dirをdebug_dirに変更\n",
    "    dataset_dir = debug_dir\n",
    "    dataset_img_dir = debug_img_dir\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n",
    "dataset_dir_name = os.path.basename(dataset_dir)\n",
    "dataset_img_dir_name = os.path.basename(dataset_img_dir)\n",
    "print(f\" data_root: {data_root}\\n dataset_dir: {dataset_dir}\\n dataset_img_dir:{dataset_img_dir}\")\n",
    "print(f\"▶ Using dataset_path : {dataset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b41182d-0e84-480a-94f5-78166f1665f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 473/473 [00:02<00:00, 230.91it/s]\n",
      "Wrote 473 images belonging to 5 classes\n",
      "Record file : data/debug_dataset/train.rec\n",
      "Index file  : data/debug_dataset/train.idx\n",
      "List file   : data/debug_dataset/train.lst\n"
     ]
    }
   ],
   "source": [
    "# ImageFolder convert to recordIO\n",
    "!python create_train_rec.py --img_dir {dataset_img_dir} --output_dir {dataset_dir}\n",
    "\n",
    "# 各評価ファイルをコピー\n",
    "!cp evaluations/agedb_30.bin \\\n",
    "   evaluations/calfw.bin \\\n",
    "   evaluations/cfp_ff.bin \\\n",
    "   evaluations/cfp_fp.bin \\\n",
    "   evaluations/cplfw.bin \\\n",
    "   evaluations/lfw.bin \\\n",
    "   {dataset_dir}/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6479a37-46df-40ac-87ee-8bbcdf10d71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading bin 1000\n",
      "loading bin 2000\n",
      "loading bin 3000\n",
      "loading bin 4000\n",
      "loading bin 5000\n",
      "loading bin 6000\n",
      "loading bin 7000\n",
      "loading bin 8000\n",
      "loading bin 9000\n",
      "loading bin 10000\n",
      "loading bin 11000\n",
      "loading bin 12000\n",
      "(12000, 3, 112, 112)\n",
      "loading bin 1000\n",
      "loading bin 2000\n",
      "loading bin 3000\n",
      "loading bin 4000\n",
      "loading bin 5000\n",
      "loading bin 6000\n",
      "loading bin 7000\n",
      "loading bin 8000\n",
      "loading bin 9000\n",
      "loading bin 10000\n",
      "loading bin 11000\n",
      "loading bin 12000\n",
      "(12000, 3, 112, 112)\n",
      "loading bin 1000\n",
      "loading bin 2000\n",
      "loading bin 3000\n",
      "loading bin 4000\n",
      "loading bin 5000\n",
      "loading bin 6000\n",
      "loading bin 7000\n",
      "loading bin 8000\n",
      "loading bin 9000\n",
      "loading bin 10000\n",
      "loading bin 11000\n",
      "loading bin 12000\n",
      "loading bin 13000\n",
      "loading bin 14000\n",
      "(14000, 3, 112, 112)\n",
      "loading bin 1000\n",
      "loading bin 2000\n",
      "loading bin 3000\n",
      "loading bin 4000\n",
      "loading bin 5000\n",
      "loading bin 6000\n",
      "loading bin 7000\n",
      "loading bin 8000\n",
      "loading bin 9000\n",
      "loading bin 10000\n",
      "loading bin 11000\n",
      "loading bin 12000\n",
      "loading bin 13000\n",
      "loading bin 14000\n",
      "(14000, 3, 112, 112)\n",
      "loading bin 1000\n",
      "loading bin 2000\n",
      "loading bin 3000\n",
      "loading bin 4000\n",
      "loading bin 5000\n",
      "loading bin 6000\n",
      "loading bin 7000\n",
      "loading bin 8000\n",
      "loading bin 9000\n",
      "loading bin 10000\n",
      "loading bin 11000\n",
      "loading bin 12000\n",
      "(12000, 3, 112, 112)\n",
      "loading bin 1000\n",
      "loading bin 2000\n",
      "loading bin 3000\n",
      "loading bin 4000\n",
      "loading bin 5000\n",
      "loading bin 6000\n",
      "loading bin 7000\n",
      "loading bin 8000\n",
      "loading bin 9000\n",
      "loading bin 10000\n",
      "loading bin 11000\n",
      "loading bin 12000\n",
      "(12000, 3, 112, 112)\n"
     ]
    }
   ],
   "source": [
    "!python AdaFace/convert.py --rec_path {dataset_dir} --make_validation_memfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062c18a9-2404-468a-8a00-9d9d5d8ade91",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a96518-1f89-4a7b-9a4a-0ae88025dcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: main.py [--data_root DATA_ROOT] [--train_data_path TRAIN_DATA_PATH]\n",
      "               [--val_data_path VAL_DATA_PATH] [--use_mxrecord]\n",
      "               [--train_data_subset] [--swap_color_channel] [--prefix PREFIX]\n",
      "               [--gpus GPUS] [--distributed_backend {dp,ddp,ddp2}]\n",
      "               [--use_16bit] [--epochs N] [--seed SEED]\n",
      "               [--batch_size BATCH_SIZE] [--lr LR]\n",
      "               [--lr_milestones LR_MILESTONES] [--lr_gamma LR_GAMMA]\n",
      "               [--num_workers NUM_WORKERS] [--fast_dev_run] [--evaluate]\n",
      "               [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "               [--start_from_model_statedict START_FROM_MODEL_STATEDICT]\n",
      "               [--use_wandb] [--custom_num_class CUSTOM_NUM_CLASS]\n",
      "               [--arch ARCH] [--momentum M] [--weight_decay WEIGHT_DECAY]\n",
      "               [--head HEAD] [--m M] [--h H] [--s S] [--t_alpha T_ALPHA]\n",
      "               [--low_res_augmentation_prob LOW_RES_AUGMENTATION_PROB]\n",
      "               [--crop_augmentation_prob CROP_AUGMENTATION_PROB]\n",
      "               [--photometric_augmentation_prob PHOTOMETRIC_AUGMENTATION_PROB]\n",
      "               [--accumulate_grad_batches ACCUMULATE_GRAD_BATCHES]\n",
      "               [--test_run] [--save_all_models]\n",
      "main.py: error: unrecognized arguments: --help\n"
     ]
    }
   ],
   "source": [
    "!python AdaFace/main.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95e9f81e-cd88-47bf-80eb-8a9612a6a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspace/AdaFace/main.py\", line 109, in <module>\n",
      "    main(args)\n",
      "  File \"/workspace/AdaFace/main.py\", line 20, in main\n",
      "    trainer_mod = train_val.Trainer(**hparams)\n",
      "  File \"/workspace/AdaFace/train_val.py\", line 18, in __init__\n",
      "    self.class_num = utils.get_num_class(self.hparams)\n",
      "  File \"/workspace/AdaFace/utils.py\", line 131, in get_num_class\n",
      "    class_folders = [d for d in os.listdir(img_dir)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/debug_dataset'\n"
     ]
    }
   ],
   "source": [
    "# !NUM_CLASSES=$(find \"${DATA_ROOT}/${DATASET_NAME}/imgs\" -mindepth 1 -maxdepth 1 -type d | wc -l)\n",
    "!python AdaFace/main.py \\\n",
    "    --data_root {data_root} \\\n",
    "    --train_data_path {dataset_dir_name} \\\n",
    "    --val_data_path {dataset_dir_name} \\\n",
    "    --prefix ir101_ms1mv2_adaface \\\n",
    "    --gpus 1 \\\n",
    "    --use_16bit \\\n",
    "    --arch ir_101 \\\n",
    "    --batch_size 216 \\\n",
    "    --num_workers 16 \\\n",
    "    --epochs 2 \\\n",
    "    --lr_milestones 12,20,24 \\\n",
    "    --lr 0.1 \\\n",
    "    --head adaface \\\n",
    "    --m 0.4 \\\n",
    "    --h 0.333 \\\n",
    "    --low_res_augmentation_prob 0.2 \\\n",
    "    --crop_augmentation_prob 0.2 \\\n",
    "    --photometric_augmentation_prob 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec416a7d-d78c-4c97-9ddd-8116bdccade2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
